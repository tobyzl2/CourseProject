{
    "artificial+intelligence": [
        {
            "title": "Proceedings of the Seventeenth Conference on Uncertainty in Artificial   Intelligence (2001)",
            "summary": "This is the Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence, which was held in Seattle, WA, August 2-5 2001"
        },
        {
            "title": "Watershed of Artificial Intelligence: Human Intelligence, Machine   Intelligence, and Biological Intelligence",
            "summary": "This article reviews the \"Once learning\" mechanism that was proposed 23 years ago and the subsequent successes of \"One-shot learning\" in image classification and \"You Only Look Once - YOLO\" in objective detection. Analyzing the current development of Artificial Intelligence (AI), the proposal is that AI should be clearly divided into the following categories: Artificial Human Intelligence (AHI), Artificial Machine Intelligence (AMI), and Artificial Biological Intelligence (ABI), which will also be the main directions of theory and application development for AI. As a watershed for the branches of AI, some classification standards and methods are discussed: 1) Human-oriented, machine-oriented, and biological-oriented AI R&amp;D; 2) Information input processed by Dimensionality-up or Dimensionality-reduction; 3) The use of one/few or large samples for knowledge learning."
        },
        {
            "title": "Human $\\neq$ AGI",
            "summary": "Terms Artificial General Intelligence (AGI) and Human-Level Artificial Intelligence (HLAI) have been used interchangeably to refer to the Holy Grail of Artificial Intelligence (AI) research, creation of a machine capable of achieving goals in a wide range of environments. However, widespread implicit assumption of equivalence between capabilities of AGI and HLAI appears to be unjustified, as humans are not general intelligences. In this paper, we will prove this distinction."
        },
        {
            "title": "AAAI FSS-18: Artificial Intelligence in Government and Public Sector   Proceedings",
            "summary": "Proceedings of the AAAI Fall Symposium on Artificial Intelligence in Government and Public Sector, Arlington, Virginia, USA, October 18-20, 2018"
        },
        {
            "title": "Hybrid Systems Knowledge Representation Using Modelling Environment   System Techniques Artificial Intelligence",
            "summary": "Knowledge-based or Artificial Intelligence techniques are used increasingly as alternatives to more classical techniques to model ENVIRONMENTAL SYSTEMS. Use of Artificial Intelligence (AI) in environmental modelling has increased with recognition of its potential. In this paper we examine the DIFFERENT TECHNIQUES of Artificial intelligence with profound examples of human perception, learning and reasoning to solve complex problems. However with the increase of complexity better methods are required. Keeping in view of the above some researchers introduced the idea of hybrid mechanism in which two or more methods can be combined which seems to be a positive effort for creating a more complex; advanced and intelligent system which has the capability to in- cooperate human decisions thus driving the landscape changes."
        },
        {
            "title": "Examining correlation between trust and transparency with explainable   artificial intelligence",
            "summary": "Trust between humans and artificial intelligence(AI) is an issue which has implications in many fields of human computer interaction. The current issue with artificial intelligence is a lack of transparency into its decision making, and literature shows that increasing transparency increases trust. Explainable artificial intelligence has the ability to increase transparency of AI, which could potentially increase trust for humans. This paper attempts to use the task of predicting yelp review star ratings with assistance from an explainable and non explainable artificial intelligence to see if trust is increased with increased transparency. Results show that for these tasks, explainable artificial intelligence provided significant increase in trust as a measure of influence."
        },
        {
            "title": "Impact of Artificial Intelligence on Economic Theory",
            "summary": "Artificial intelligence has impacted many aspects of human life. This paper studies the impact of artificial intelligence on economic theory. In particular we study the impact of artificial intelligence on the theory of bounded rationality, efficient market hypothesis and prospect theory."
        },
        {
            "title": "Intelligence Quotient and Intelligence Grade of Artificial Intelligence",
            "summary": "Although artificial intelligence is currently one of the most interesting areas in scientific research, the potential threats posed by emerging AI systems remain a source of persistent controversy. To address the issue of AI threat, this study proposes a standard intelligence model that unifies AI and human characteristics in terms of four aspects of knowledge, i.e., input, output, mastery, and creation. Using this model, we observe three challenges, namely, expanding of the von Neumann architecture; testing and ranking the intelligence quotient of naturally and artificially intelligent systems, including humans, Google, Bing, Baidu, and Siri; and finally, the dividing of artificially intelligent systems into seven grades from robots to Google Brain. Based on this, we conclude that AlphaGo belongs to the third grade."
        },
        {
            "title": "Building Safer AGI by introducing Artificial Stupidity",
            "summary": "Artificial Intelligence (AI) achieved super-human performance in a broad variety of domains. We say that an AI is made Artificially Stupid on a task when some limitations are deliberately introduced to match a human's ability to do the task. An Artificial General Intelligence (AGI) can be made safer by limiting its computing power and memory, or by introducing Artificial Stupidity on certain tasks. We survey human intellectual limits and give recommendations for which limits to implement in order to build a safe AGI."
        },
        {
            "title": "Decision under Uncertainty",
            "summary": "We derive axiomatically the probability function that should be used to make decisions given any form of underlying uncertainty."
        }
    ],
    "hardware+architecture": [
        {
            "title": "The Hardware Lottery",
            "summary": "Hardware, systems and algorithms research communities have historically had different incentive structures and fluctuating motivation to engage with each other explicitly. This historical treatment is odd given that hardware and software have frequently determined which research ideas succeed (and fail). This essay introduces the term hardware lottery to describe when a research idea wins because it is suited to the available software and hardware and not because the idea is superior to alternative research directions. Examples from early computer science history illustrate how hardware lotteries can delay research progress by casting successful ideas as failures. These lessons are particularly salient given the advent of domain specialized hardware which make it increasingly costly to stray off of the beaten path of research ideas. This essay posits that the gains from progress in computing are likely to become even more uneven, with certain research directions moving into the fast-lane while progress on others is further obstructed."
        },
        {
            "title": "Pre-Quantized Deep Learning Models Codified in ONNX to Enable   Hardware/Software Co-Design",
            "summary": "This paper presents a methodology to separate the quantization process from the hardware-specific model compilation stage via a pre-quantized deep learning model description in standard ONNX format. Separating the quantization process from the model compilation stage enables independent development. The methodology is expressive to convey hardware-specific operations and to embed key quantization parameters into a ONNX model which enables hardware/software co-design. Detailed examples are given for both MLP and CNN based networks, which can be extended to other networks in a straightforward fashion."
        },
        {
            "title": "SAPA: Self-Aware Polymorphic Architecture",
            "summary": "In this work, we introduce a Self-Aware Polymorphic Architecture (SAPA) design approach to support emerging context-aware applications and mitigate the programming challenges caused by the ever-increasing complexity and heterogeneity of high performance computing systems. Through the SAPA design, we examined the salient software-hardware features of adaptive computing systems that allow for (1) the dynamic allocation of computing resources depending on program needs (e.g., the amount of parallelism in the program) and (2) automatic approximation to meet program and system goals (e.g., execution time budget, power constraints and computation resiliency) without the programming complexity of current multicore and many-core systems. The proposed adaptive computer architecture framework applies machine learning algorithms and control theory techniques to the application execution based on information collected about the system runtime performance trade-offs. It has heterogeneous reconfigurable cores with fast hardware-level migration capability, self-organizing memory structures and hierarchies, an adaptive application-aware network-on-chip, and a built-in hardware layer for dynamic, autonomous resource management. Our prototyped architecture performs extremely well on a large pool of applications."
        },
        {
            "title": "Does Form Follow Function? An Empirical Exploration of the Impact of   Deep Neural Network Architecture Design on Hardware-Specific Acceleration",
            "summary": "The fine-grained relationship between form and function with respect to deep neural network architecture design and hardware-specific acceleration is one area that is not well studied in the research literature, with form often dictated by accuracy as opposed to hardware function. In this study, a comprehensive empirical exploration is conducted to investigate the impact of deep neural network architecture design on the degree of inference speedup that can be achieved via hardware-specific acceleration. More specifically, we empirically study the impact of a variety of commonly used macro-architecture design patterns across different architectural depths through the lens of OpenVINO microprocessor-specific and GPU-specific acceleration. Experimental results showed that while leveraging hardware-specific acceleration achieved an average inference speed-up of 380%, the degree of inference speed-up varied drastically depending on the macro-architecture design pattern, with the greatest speedup achieved on the depthwise bottleneck convolution design pattern at 550%. Furthermore, we conduct an in-depth exploration of the correlation between FLOPs requirement, level 3 cache efficacy, and network latency with increasing architectural depth and width. Finally, we analyze the inference time reductions using hardware-specific acceleration when compared to native deep learning frameworks across a wide variety of hand-crafted deep convolutional neural network architecture designs as well as ones found via neural architecture search strategies. We found that the DARTS-derived architecture to benefit from the greatest improvement from hardware-specific software acceleration (1200%) while the depthwise bottleneck convolution-based MobileNet-V2 to have the lowest overall inference time of around 2.4 ms."
        },
        {
            "title": "Tejas Simulator : Validation against Hardware",
            "summary": "In this report we show results that validate the Tejas architectural simulator against native hardware. We report mean error rates of 11.45% and 18.77% for the SPEC2006 and Splash2 benchmark suites respectively. These error rates are competitive and in most cases better than the numbers reported by other contemporary simulators."
        },
        {
            "title": "Scalable NoC-based Neuromorphic Hardware Learning and Inference",
            "summary": "Bio-inspired neuromorphic hardware is a research direction to approach brain's computational power and energy efficiency. Spiking neural networks (SNN) encode information as sparsely distributed spike trains and employ spike-timing-dependent plasticity (STDP) mechanism for learning. Existing hardware implementations of SNN are limited in scale or do not have in-hardware learning capability. In this work, we propose a low-cost scalable Network-on-Chip (NoC) based SNN hardware architecture with fully distributed in-hardware STDP learning capability. All hardware neurons work in parallel and communicate through the NoC. This enables chip-level interconnection, scalability and reconfigurability necessary for deploying different applications. The hardware is applied to learn MNIST digits as an evaluation of its learning capability. We explore the design space to study the trade-offs between speed, area and energy. How to use this procedure to find optimal architecture configuration is also discussed."
        },
        {
            "title": "Microgrid - The microthreaded many-core architecture",
            "summary": "Traditional processors use the von Neumann execution model, some other processors in the past have used the dataflow execution model. A combination of von Neuman model and dataflow model is also tried in the past and the resultant model is referred as hybrid dataflow execution model. We describe a hybrid dataflow model known as the microthreading. It provides constructs for creation, synchronization and communication between threads in an intermediate language. The microthreading model is an abstract programming and machine model for many-core architecture. A particular instance of this model is named as the microthreaded architecture or the Microgrid. This architecture implements all the concurrency constructs of the microthreading model in the hardware with the management of these constructs in the hardware."
        },
        {
            "title": "ISyNet: Convolutional Neural Networks design for AI accelerator",
            "summary": "In recent years Deep Learning reached significant results in many practical problems, such as computer vision, natural language processing, speech recognition and many others. For many years the main goal of the research was to improve the quality of models, even if the complexity was impractically high. However, for the production solutions, which often require real-time work, the latency of the model plays a very important role. Current state-of-the-art architectures are found with neural architecture search (NAS) taking model complexity into account. However, designing of the search space suitable for specific hardware is still a challenging task. To address this problem we propose a measure of hardware efficiency of neural architecture search space - matrix efficiency measure (MEM); a search space comprising of hardware-efficient operations; a latency-aware scaling method; and ISyNet - a set of architectures designed to be fast on the specialized neural processing unit (NPU) hardware and accurate at the same time. We show the advantage of the designed architectures for the NPU devices on ImageNet and the generalization ability for the downstream classification and detection tasks."
        },
        {
            "title": "ProxylessNAS: Direct Neural Architecture Search on Target Task and   Hardware",
            "summary": "Neural architecture search (NAS) has a great impact by automatically designing effective neural network architectures. However, the prohibitive computational demand of conventional NAS algorithms (e.g. $10^4$ GPU hours) makes it difficult to \\emph{directly} search the architectures on large-scale tasks (e.g. ImageNet). Differentiable NAS can reduce the cost of GPU hours via a continuous representation of network architecture but suffers from the high GPU memory consumption issue (grow linearly w.r.t. candidate set size). As a result, they need to utilize~\\emph{proxy} tasks, such as training on a smaller dataset, or learning with only a few blocks, or training just for a few epochs. These architectures optimized on proxy tasks are not guaranteed to be optimal on the target task. In this paper, we present \\emph{ProxylessNAS} that can \\emph{directly} learn the architectures for large-scale target tasks and target hardware platforms. We address the high memory consumption issue of differentiable NAS and reduce the computational cost (GPU hours and GPU memory) to the same level of regular training while still allowing a large candidate set. Experiments on CIFAR-10 and ImageNet demonstrate the effectiveness of directness and specialization. On CIFAR-10, our model achieves 2.08\\% test error with only 5.7M parameters, better than the previous state-of-the-art architecture AmoebaNet-B, while using 6$\\times$ fewer parameters. On ImageNet, our model achieves 3.1\\% better top-1 accuracy than MobileNetV2, while being 1.2$\\times$ faster with measured GPU latency. We also apply ProxylessNAS to specialize neural architectures for hardware with direct hardware metrics (e.g. latency) and provide insights for efficient CNN architecture design."
        },
        {
            "title": "Agile SoC Development with Open ESP",
            "summary": "ESP is an open-source research platform for heterogeneous SoC design. The platform combines a modular tile-based architecture with a variety of application-oriented flows for the design and optimization of accelerators. The ESP architecture is highly scalable and strikes a balance between regularity and specialization. The companion methodology raises the level of abstraction to system-level design and enables an automated flow from software and hardware development to full-system prototyping on FPGA. For application developers, ESP offers domain-specific automated solutions to synthesize new accelerators for their software and to map complex workloads onto the SoC architecture. For hardware engineers, ESP offers automated solutions to integrate their accelerator designs into the complete SoC. Conceived as a heterogeneous integration platform and tested through years of teaching at Columbia University, ESP supports the open-source hardware community by providing a flexible platform for agile SoC development."
        }
    ],
    "computer+security": [
        {
            "title": "Security Policy Consistency",
            "summary": "With the advent of wide security platforms able to express simultaneously all the policies comprising an organization's global security policy, the problem of inconsistencies within security policies become harder and more relevant.   We have defined a tool based on the CHR language which is able to detect several types of inconsistencies within and between security policies and other specifications, namely workflow specifications.   Although the problem of security conflicts has been addressed by several authors, to our knowledge none has addressed the general problem of security inconsistencies, on its several definitions and target specifications."
        },
        {
            "title": "Emerging Security Challenges of Cloud Virtual Infrastructure",
            "summary": "The cloud computing model is rapidly transforming the IT landscape. Cloud computing is a new computing paradigm that delivers computing resources as a set of reliable and scalable internet-based services allowing customers to remotely run and manage these services. Infrastructure-as-a-service (IaaS) is one of the popular cloud computing services. IaaS allows customers to increase their computing resources on the fly without investing in new hardware. IaaS adapts virtualization to enable on-demand access to a pool of virtual computing resources. Although there are great benefits to be gained from cloud computing, cloud computing also enables new categories of threats to be introduced. These threats are a result of the cloud virtual infrastructure complexity created by the adoption of the virtualization technology.   Breaching the security of any component in the cloud virtual infrastructure significantly impacts on the security of other components and consequently affects the overall system security. This paper explores the security problem of the cloud platform virtual infrastructure identifying the existing security threats and the complexities of this virtual infrastructure. The paper also discusses the existing security approaches to secure the cloud virtual infrastructure and their drawbacks. Finally, we propose and explore some key research challenges of implementing new virtualization-aware security solutions that can provide the pre-emptive protection for complex and ever- dynamic cloud virtual infrastructure."
        },
        {
            "title": "M-Banking Security - a futuristic improved security approach",
            "summary": "In last few decades large technology development raised various new needs. Financial sector has also no exception. People are approaching all over the world to fulfill there dreams. Any sector needs to understand changing need of customer. In order to satisfy financial need for customer banks are taking help of new technology such as internet. Only problem remain is of security. The aim of this work is to provide a secure environment in terms of security for transaction by various ways. In order to improve security we are making use of \"Steganography\" technique in the way never used before. Task of enhancing security include construction of formula for both data encryption and also for hiding pattern. Server should not process any fake request hence concept of custom \"Session id\" and \"Request id\" is introduced. Implementation of such a security constraints in banking sector not only help to serve customer in better way but also make customer confident and satisfy."
        },
        {
            "title": "What Should be Hidden and Open in Computer Security: Lessons from   Deception, the Art of War, Law, and Economic Theory",
            "summary": "\"What Should be Hidden and Open in Computer Security: Lessons from Deception, the Art of War, Law, and Economic Theory\" Peter P. Swire, George Washington University.   Imagine a military base. It is defended against possible attack. Do we expect the base to reveal the location of booby traps and other defenses? No. But for many computer applications,a software developer will need to reveal a great deal about the code to get other system owners to trust the code and know how to operate with it.   This article examines these conflicting intuitions and develops a theory about what should be open and hidden in computer security. Part I of the paper shows how substantial openness is typical for major computer security topics, such as firewalls, packaged software, and encryption. Part II shows what factors will lead to openness or hiddenness in computer security.   Part III presents an economic analysis of the issue of what should be open in computer security. The owner who does not reveal the booby traps is like a monopolist, while the open-source software supplier is in a competitive market. This economic approach allows us to identify possible market failures in how much openness occurs for computer security.   Part IV examines the contrasting approaches of Sun Tzu and Clausewitz to the role of hiddenness and deception in military strategy. The computer security, economic, and military strategy approaches thus each show factors relevant to what should be kept hidden in computer security. Part V then applies the theory to a range of current legal and technical issues."
        },
        {
            "title": "Cloud Security Architecture and Implementation - A practical approach",
            "summary": "While cloud computing provides lower Infrastructure cost, higher agility and faster delivery, it also presents higher operational and security risks for business critical assets, but a well-designed solution and security architecture will keep businesses safe during and after migrating their assets to the cloud. This paper has researched and identified best security practices and how to improve a security architecture in a cloud environment."
        },
        {
            "title": "A Multi-Vocal Review of Security Orchestration",
            "summary": "Organizations use diverse types of security solutions to prevent cyberattacks. Multiple vendors provide security solutions developed using heterogeneous technologies and paradigms. Hence, it is a challenging rather impossible to easily make security solutions to work an integrated fashion. Security orchestration aims at smoothly integrating multivendor security tools that can effectively and efficiently interoperate to support security staff of a Security Operation Centre (SOC). Given the increasing role and importance of security orchestration, there has been an increasing amount of literature on different aspects of security orchestration solutions. However, there has been no effort to systematically review and analyze the reported solutions. We report a Multivocal Literature Review that has systematically selected and reviewed both academic and grey (blogs, web pages, white papers) literature on different aspects of security orchestration published from January 2007 until July 2017. The review has enabled us to provide a working definition of security orchestration and classify the main functionalities of security orchestration into three main areas: unification, orchestration, and automation. We have also identified the core components of a security orchestration platform and categorized the drivers of security orchestration based on technical and socio-technical aspects. We also provide a taxonomy of security orchestration based on the execution environment, automation strategy, deployment type, mode of task and resource type. This review has helped us to reveal several areas of further research and development in security orchestration."
        },
        {
            "title": "Computer Security: Competing Concepts",
            "summary": "This paper focuses on a tension we discovered in the philosophical part of our multidisciplinary project on values in web-browser security. Our project draws on the methods and perspectives of empirical social science, computer science, and philosophy to identify values embodied in existing web-browser security and also to prescribe changes to existing systems (in particular, Mozilla) so that values relevant to web-browser systems are better served than presently they are. The tension, which we had not seen explicitly addressed in any other work on computer security, emerged when we set out to extract from the concept of security the set values that ought to guide the shape of web-browser security. We found it impossible to construct an internally consistent set of values until we realized that two robust -- and in places competing -- conceptions of computer security were influencing our thinking. We needed to pry these apart and make a primary commitment to one. One conception of computer security invokes the ordinary meaning of security. According to it, computer security should protect people -- computer users -- against dangers, harms, and threats. Clearly this ordinary conception of security is already informing much of the work and rhetoric surrounding computer security. But another, substantively richer conception, also defines the aims and trajectory of computer security -- computer security as an element of national security. Although, like the ordinary conception, this one is also concerned with protection against threats, its primary subject is the state, not the individual. The two conceptions suggest divergent system-specifications, not for all mechanisms but a significant few."
        },
        {
            "title": "Towards a Security Engineering Process Model for Electronic Business   Processes",
            "summary": "Business process management (BPM) and accompanying systems aim at enabling enterprises to become adaptive. In spite of the dependency of enterprises on secure business processes, BPM languages and techniques provide only little support for security. Several complementary approaches have been proposed for security in the domain of BPM. Nevertheless, support for a systematic procedure for the development of secure electronic business processes is still missing. In this paper, we pinpoint the need for a security engineering process model in the domain of BPM and identify key requirements for such process model."
        },
        {
            "title": "A Modified ck-Secure Sum Protocol for Multi-Party Computation",
            "summary": "Secure Multi-Party Computation (SMC) allows multiple parties to compute some function of their inputs without disclosing the actual inputs to one another. Secure sum computation is an easily understood example and the component of the various SMC solutions. Secure sum computation allows parties to compute the sum of their individual inputs without disclosing the inputs to one another. In this paper, we propose a modified version of our ck-Secure Sum protocol with more security when a group of the computing parties conspire to know the data of some party."
        },
        {
            "title": "Security Protocols in a Nutshell",
            "summary": "Security protocols are building blocks in secure communications. They deploy some security mechanisms to provide certain security services. Security protocols are considered abstract when analyzed, but they can have extra vulnerabilities when implemented. This manuscript provides a holistic study on security protocols. It reviews foundations of security protocols, taxonomy of attacks on security protocols and their implementations, and different methods and models for security analysis of protocols. Specifically, it clarifies differences between information-theoretic and computational security, and computational and symbolic models. Furthermore, a survey on computational security models for authenticated key exchange (AKE) and password-authenticated key exchange (PAKE) protocols, as the most important and well-studied type of security protocols, is provided."
        }
    ],
    "databases": [
        {
            "title": "Data Base Mappings and Theory of Sketches",
            "summary": "In this paper we will present the two basic operations for database schemas used in database mapping systems (separation and Data Federation), and we will explain why the functorial semantics for database mappings needed a new base category instead of usual Set category. Successively, it is presented a definition of the graph G for a schema database mapping system, and the definition of its sketch category Sch(G). Based on this framework we presented functorial semantics for database mapping systems with the new base category DB."
        },
        {
            "title": "Integrated ERP System for Improving the Functional efficiency of the   organization by Customized Architecture",
            "summary": "An ERP is a kind of package which consist front end and backend as DBMS like a collection of DBMSs. You can create DBMS to manage one aspect of your business. For example, a publishing house has a database of books that keeps information about books such as Author Name, Title, Translator Name, etc. But this database app only helps enter books data and search them. It doesn't help them, for example, sell books. They get or develop another DBMS database that has all the Books data plus prices, discount formulas, names of common clients, etc. Now they connect the Books database to Sales database and maybe also the inventory database. Now its DBMS slowly turning into an ERP. They may add payroll database and connect it to this ERP. They may develop sales staff and commissions database and connect it to this ERP and so on. In the traditional Database management system the different databases are used for the various Campuses of the JSPM Group of Education like Wagholi Campus, Tathwade Campus, Narhe Campus, Hadpsar Campuses, Bhavdhan Campus as well as Corporate office at Katraj of same organization so it is not possible to keep different databases for the same so in this paper proposed the use of Integrated Database for the Entire organization using ERP system. The Proposed ERP system applied on the existing Architecture of the JSPM Group; the marginal difference observed in the Databases need to be accessed to generate the same number of Reports when use the Traditional DBMS which end up with improvement in the Functional efficiency of Organizational Architecture."
        },
        {
            "title": "Differentially-Private Fingerprinting of Relational Databases",
            "summary": "When sharing sensitive databases with other parties, a database owner aims to (i) have privacy guarantees for its shared database, (ii) have liability guarantees in case of unauthorized sharing of its database by the recipients, and (iii) provide a high quality (utility) database to the recipients. We observe that sharing a database under differential privacy and database fingerprinting are orthogonal objectives. The former aims to inject noise into a database to prevent inference of the original data values, whereas, the latter aims to hide unique marks inside a database to trace malicious parties who leak the data without the authorization. In this paper, we achieve these two objectives simultaneously by proposing a novel differentially-private fingerprinting mechanism for databases.   Specifically, we first devise a bit-level random response scheme to achieve differential privacy for sharing entire databases, and then, based on this, we develop an {\\epsilon}-differentially private fingerprinting mechanism. Next, we theoretically analyze the relationships among differential privacy guarantee, fingerprint robustness, and database utility by deriving closed form expressions to characterize the privacy-utility coupling and privacy-fingerprint robustness coupling. Furthermore, we propose a sparse vector technique (SVT)-based solution to control the cumulative privacy loss when fingerprinted copies of a database are shared with multiple recipients. We experimentally show that our mechanism achieves stronger fingerprint robustness than the state-of-the-art fingerprinting mechanisms, and higher database utility than the simple composition of database perturbation under differential privacy followed by fingerprinting (e.g., statistical utility of the shared database by the proposed scheme is more than 10x higher than perturbation followed by fingerprinting)."
        },
        {
            "title": "MINE GOLD to Deliver Green Cognitive Communications",
            "summary": "Geo-location database-assisted TV white space network reduces the need of energy-intensive processes (such as spectrum sensing), hence can achieve green cognitive communication effectively. The success of such a network relies on a proper business model that provides incentives for all parties involved. In this paper, we propose MINE GOLD (a Model of INformation markEt for GeO-Location Database), which enables databases to sell the spectrum information to unlicensed white space devices (WSDs) for profit. Specifically, we focus on an oligopoly information market with multiple databases, and study the interactions among databases and WSDs using a two-stage hierarchical model. In Stage I, databases compete to sell information to WSDs by optimizing their information prices. In Stage II, each WSD decides whether and from which database to purchase the information, to maximize his benefit of using the TV white space. We first characterize how the WSDs' purchasing behaviors dynamically evolve, and what is the equilibrium point under fixed information prices from the databases. We then analyze how the system parameters and the databases' pricing decisions affect the market equilibrium, and what is the equilibrium of the database price competition. Our numerical results show that, perhaps counter-intuitively, the databases' aggregate revenue is not monotonic with the number of databases. Moreover, numerical results show that a large degree of positive network externality would improve the databases' revenues and the system performance."
        },
        {
            "title": "Discover Aggregates Exceptions over Hidden Web Databases",
            "summary": "Nowadays, many web databases \"hidden\" behind their restrictive search interfaces (e.g., Amazon, eBay) contain rich and valuable information that is of significant interests to various third parties. Recent studies have demonstrated the possibility of estimating/tracking certain aggregate queries over dynamic hidden web databases. Nonetheless, tracking all possible aggregate query answers to report interesting findings (i.e., exceptions), while still adhering to the stringent query-count limitations enforced by many hidden web databases providers, is very challenging. In this paper, we develop a novel technique for tracking and discovering exceptions (in terms of sudden changes of aggregates) over dynamic hidden web databases. Extensive real-world experiments demonstrate the superiority of our proposed algorithms over baseline solutions."
        },
        {
            "title": "A Logical Formalization of a Secure XML Database",
            "summary": "In this paper, we first define a logical theory representing an XML database supporting XPath as query language and XUpdate as modification language. We then extend our theory with predicates allowing us to specify the security policy protecting the database. The security policy includes rules addressing the read and write privileges. We propose axioms to derive the database view each user is permitted to see. We also propose axioms to derive the new database content after an update."
        },
        {
            "title": "Proposing Cluster_Similarity Method in Order to Find as Much Better   Similarities in Databases",
            "summary": "Different ways of entering data into databases result in duplicate records that cause increasing of databases' size. This is a fact that we cannot ignore it easily. There are several methods that are used for this purpose. In this paper, we have tried to increase the accuracy of operations by using cluster similarity instead of direct similarity of fields. So that clustering is done on fields of database and according to accomplished clustering on fields, similarity degree of records is obtained. In this method by using present information in database, more logical similarity is obtained for deficient information that in general, the method of cluster similarity could improve operations 24% compared with previous methods."
        },
        {
            "title": "The CTU Prague Relational Learning Repository",
            "summary": "The aim of the CTU Prague Relational Learning Repository is to support machine learning research with multi-relational data. The repository currently contains 50 SQL databases hosted on a public MySQL server located at relational.fit.cvut.cz. A searchable meta-database provides metadata (e.g., the number of tables in the database, the number of rows and columns in the tables, the number of foreign key constraints between tables)."
        },
        {
            "title": "The Journal Coverage of Web of Science, Scopus and Dimensions: A   Comparative Analysis",
            "summary": "Traditionally, Web of Science and Scopus have been the two most widely used databases for bibliometric analyses. However, during the last few years some new scholarly databases, such as Dimensions, have come up. Several previous studies have compared different databases, either through a direct comparison of article coverage or by comparing the citations across the databases. This article attempts to compare the journal coverage of the three databases: Web of Science, Scopus and Dimensions. The most recent master journal lists of the three databases have been used for the purpose of identifying the overlapping and unique journals covered in the databases. The results indicate that the databases have significantly different journal coverage, with the Web of Science being most selective and Dimensions being the most exhaustive. About 99.11% and 96.61% of the journals indexed in Web of Science are also indexed in Scopus and Dimensions, respectively. Scopus has 96.42% of its indexed journals also covered by Dimensions. Dimensions database has the most exhaustive coverage, with 82.22% more journals covered as compared to Web of Science and 48.17% more journals covered as compared to Scopus. We also analysed the research outputs for 20 highly productive countries for the 2010-2019 period, as indexed in the three databases, and identified database-induced variations in research output volume, rank and global share of different countries. In addition to variations in overall coverage of research output from different countries, the three databases appear to have differential coverage of different disciplines."
        },
        {
            "title": "Firebird Database Backup by Serialized Database Table Dump",
            "summary": "This paper presents a simple data dump and load utility for Firebird databases which mimics mysqldump in MySQL. This utility, fb_dump and fb_load, for dumping and loading respectively, retrieves each database table using kinterbasdb and serializes the data using marshal module. This utility has two advantages over the standard Firebird database backup utility, gbak. Firstly, it is able to backup and restore single database tables which might help to recover corrupted databases. Secondly, the output is in text-coded format (from marshal module) making it more resilient than a compressed text backup, as in the case of using gbak."
        }
    ],
    "formal+languages+and+automata+theory": [
        {
            "title": "Convex Language Semantics for Nondeterministic Probabilistic Automata",
            "summary": "We explore language semantics for automata combining probabilistic and nondeterministic behavior. We first show that there are precisely two natural semantics for probabilistic automata with nondeterminism. For both choices, we show that these automata are strictly more expressive than deterministic probabilistic automata, and we prove that the problem of checking language equivalence is undecidable by reduction from the threshold problem. However, we provide a discounted metric that can be computed to arbitrarily high precision."
        },
        {
            "title": "Orbit-Finite-Dimensional Vector Spaces and Weighted Register Automata",
            "summary": "We develop a theory of vector spaces spanned by orbit-finite sets. Using this theory, we give a decision procedure for equivalence of weighted register automata, which are the common generalization of weighted automata and register automata for infinite alphabets. The algorithm runs in exponential time, and in polynomial time for a fixed number of registers. As a special case, we can decide, with the same complexity, language equivalence for unambiguous register automata, which improves previous results in three ways: (a) we allow for order comparisons on atoms, and not just equality; (b) the complexity is exponentially better; and (c) we allow automata with guessing."
        },
        {
            "title": "Monoid automata for displacement context-free languages",
            "summary": "In 2007 Kambites presented an algebraic interpretation of Chomsky-Sch\u007futzenberger theorem for context-free languages. We give an interpretation of the corresponding theorem for the class of displacement context-free languages which are equivalent to well-nested multiple context-free languages. We also obtain a characterization of k-displacement context-free languages in terms of monoid automata and show how such automata can be simulated on two stacks. We introduce the simultaneous two-stack automata and compare different variants of its definition. All the definitions considered are shown to be equivalent basing on the geometric interpretation of memory operations of these automata."
        },
        {
            "title": "LTL to Smaller Self-Loop Alternating Automata and Back",
            "summary": "Self-loop alternating automata (SLAA) with B\\\"uchi or co-B\\\"uchi acceptance are popular intermediate formalisms in translations of LTL to deterministic or nondeterministic automata. This paper considers SLAA with generic transition-based Emerson-Lei acceptance and presents translations of LTL to these automata and back. Importantly, the translation of LTL to SLAA with generic acceptance produces considerably smaller automata than previous translations of LTL to B\\\"uchi or co-B\\\"uchi SLAA. Our translation is already implemented in the tool LTL3TELA, where it helps to produce small deterministic or nondeterministic automata for given LTL formulae."
        },
        {
            "title": "On Typical Hesitant Fuzzy Languages and Automata",
            "summary": "The idea of nondeterministic typical hesitant fuzzy automata is a generalization of the fuzzy automata presented by Costa and Bedregal. This paper, presents the sufficient and necessary conditions for a typical hesitant fuzzy language to be computed by nondeterministic typical hesitant fuzzy automata. Besides, the paper introduces a new class of Typical Hesitant Fuzzy Automata with crisp transitions, and we will show that this new class is equivalent to the original class introduced by Costa and Bedregal"
        },
        {
            "title": "On Stochastic Automata over Monoids",
            "summary": "Stochastic automata over monoids as input sets are studied. The well-definedness of these automata requires an extension postulate that replaces the inherent universal property of free monoids. As a generalization of Turakainen's result, it will be shown that the generalized automata over monoids have the same acceptance power as their stochastic counterparts. The key to homomorphisms is a commuting property between the monoid homomorphism of input states and the monoid homomorphism of transition matrices. Closure properties of the languages accepted by stochastic automata over monoids are investigated. matrices. Closure properties of the languages accepted by stochastic automata over monoids are investigated."
        },
        {
            "title": "Automata and automata mappings of semigroups",
            "summary": "The paper is devoted to two types of algebraic models of automata. The usual (first type) model leads to the developed decomposition theory (Krohn-Rhodes theory). We introduce another type of automata model and study how these automata are related to cascade connections of automata of the first type. The introduced automata play a significant role in group theory and, hopefully, in the theory of formal languages."
        },
        {
            "title": "A Linear Acceleration Theorem for 2D Cellular Automata on all Complete   Neighborhoods",
            "summary": "Linear acceleration theorems are known for most computational models. Although such results have been proved for two-dimensional cellular automata working on specific neighborhoods, no general construction was known. We present here a technique of linear acceleration for all two-dimensional languages recognized by cellular automata working on complete neighborhoods."
        },
        {
            "title": "Answers to Questions Formulated in the Paper \"On States Observability in   Deterministic Finite Automata\"",
            "summary": "This paper gives answers to questions formulated as open in the paper \"On State Observability in Deterministic Finite Automata\" by A. Mateescu and Gh. Paun. Specifically, it demonstrates that for all k &gt;= 2, the families of regular languages acceptable by deterministic finite automata with no more than k semi-observable states, denoted by Tk, are anti-AFL's, and that the family T1 differs in the closure property under Kleene +."
        },
        {
            "title": "About the embedding of one dimensional cellular automata into hyperbolic   cellular automata",
            "summary": "In this paper, we look at two ways to implement determinisitic one dimensional cellular automata into hyperbolic cellular automata in three contexts: the pentagrid, the heptagrid and the dodecagrid, these tilings being classically denoted by $\\{5,4\\}$, $\\{7,3\\}$ and $\\{5,3,4\\}$ respectively."
        }
    ],
    "operating+systems": [
        {
            "title": "Windows And Linux Operating Systems From A Security Perspective",
            "summary": "Operating systems are vital system software that, without them, humans would not be able to manage and use computer systems. In essence, an operating system is a collection of software programs whose role is to manage computer resources and provide an interface for client applications to interact with the different computer hardware. Most of the commercial operating systems available today on the market have buggy code and they exhibit security flaws and vulnerabilities. In effect, building a trusted operating system that can mostly resist attacks and provide a secure computing environment to protect the important assets of a computer is the goal of every operating system manufacturer. This paper deeply investigates the various security features of the two most widespread and successful operating systems, Microsoft Windows and Linux. The different security features, designs, and components of the two systems are to be covered elaborately, pin-pointing the key similarities and differences between them. In due course, a head-to-head comparison is to be drawn for each security aspect, exposing the advantage of one system over the other."
        },
        {
            "title": "Groups of Operators for Evolution Equations of Quantum Many-Particle   Systems",
            "summary": "The aim of this work is to study the properties of groups of operators for evolution equations of quantum many-particle systems, namely, the von Neumann hierarchy for correlation operators, the BBGKY hierarchy for marginal density operators and the dual BBGKY hierarchy for marginal observables. We show that the concept of cumulants (semi-invariants) of groups of operators for the von Neumann equations forms the basis of the expansions for one-parametric families of operators for evolution equations of infinitely many particles."
        },
        {
            "title": "Universal quantum computing with superconducting charge qubits",
            "summary": "Superconducting quantum circuit is a promising system for building quantum computer. With this system we demonstrate the universal quantum computations, including the preparing of initial states, the single-qubit operations, the two-qubit universal gate operations between arbitrary qubits, the multiple pairs of two-qubit gate operations in parallel, the coupling operations on a group of qubits in parallel, the coupling operations on multiple groups of qubits in parallel, the coupling operations on multiple pairs and multiple groups of qubits in parallel. Within available technology, a universal quantum computer consists of more than 50 qubits allowing operations is achievable with the design."
        },
        {
            "title": "Integrable Operators and Canonical Differential Systems",
            "summary": "In this article we consider a class of integrable operators and investigate its connections with the following theories:the spectral theory of non-self-adjoint operators, the Riemann-Hilbert problem, the canonical differential systems and the random matrices theory."
        },
        {
            "title": "Koopman Operator Methods for Global Phase Space Exploration of   Equivariant Dynamical Systems",
            "summary": "In this paper, we develop the Koopman operator theory for dynamical systems with symmetry. In particular, we investigate how the Koopman operator and eigenfunctions behave under the action of the symmetry group of the underlying dynamical system. Further, exploring the underlying symmetry, we propose an algorithm to construct a global Koopman operator from local Koopman operators. In particular, we show, by exploiting the symmetry, data from all the invariant sets are not required for constructing the global Koopman operator; that is, local knowledge of the system is enough to infer the global dynamics."
        },
        {
            "title": "Operator system quotients of matrix algebras and their tensor products",
            "summary": "An operator system modulo the kernel of a completely positive linear map of the operator system gives rise to an operator system quotient. In this paper, operator system quotients and quotient maps of certain matrix algebras are considered. Some applications to operator algebra theory are given, including a new proof of Kirchberg's theorem on the tensor product of B(H) with the group C*-algebra of a countable free group. We also show that an affirmative solution to the Connes Embedding Problem is implied by various matrix-theoretic problems, and we give a new characterisation of unital C*-algebras that have the weak expectation property."
        },
        {
            "title": "Hypercyclic behavior of some non-convolution operators on   $H(\\mathbb{C}^N)$",
            "summary": "We study hypercyclicity properties of a family of non-convolution operators defined on spaces of holomorphic functions on $\\mathbb{C}^N$. These operators are a composition of a differentiation operator and an affine composition operator, and are analogues of operators studied by Aron and Markose on $H(\\mathbb{C})$. The hypercyclic behavior is more involved than in the one dimensional case, and depends on several parameters involved."
        },
        {
            "title": "Cherednik operators and Ruijsenaars-Schneider model at infinity",
            "summary": "Heckman introduced $N$ operators on the space of polynomials in $N$ variables, such that these operators form a covariant set relative to permutations of the operators and variables, and such that Jack symmetric polynomials are eigenfunctions of the power sums of these operators. We introduce the analogues of these $N$ operators for Macdonald symmetric polynomials, by using Cherednik operators. The latter operators pairwise commute, and Macdonald polynomials are eigenfunctions of their power sums. We compute the limits of our operators at $N\\to\\infty$. These limits yield the same Lax operator for Macdonald symmetric functions as constructed in our previous work."
        },
        {
            "title": "On the definition of a theoretical concept of an operating system",
            "summary": "We dwell on how a definition of a theoretical concept of an operating system, suitable to be incorporated in a mathematical theory of operating systems, could look like. This is considered a valuable preparation for the development of a mathematical theory of operating systems."
        },
        {
            "title": "Morita equivalence for operator systems",
            "summary": "We define $\\Delta$-equivalence for operator systems and show that it is identical to stable isomorphism. We define $\\Delta$-contexts and bihomomorphism contexts and show that two operator systems are $\\Delta$-equivalent if and only if they can be placed in a $\\Delta$-context, equivalently, in a bihomomorphism context. We show that nuclearity for a variety of tensor products is an invariant for $\\Delta$-equivalence and that function systems are $\\Delta$-equivalent precisely when they are order isomorphic. We prove that $\\Delta$-equivalent operator systems have equivalent categories of representations. As an application, we characterise $\\Delta$-equivalence of graph operator systems in combinatorial terms. We examine a notion of Morita embedding for operator systems, showing that mutually $\\Delta$-embeddable operator systems have orthogonally complemented $\\Delta$-equivalent corners."
        }
    ],
    "computer+networking": [
        {
            "title": "An Overview on the Application of Graph Neural Networks in Wireless   Networks",
            "summary": "With the rapid enhancement of computer computing power, deep learning methods, e.g., convolution neural networks, recurrent neural networks, etc., have been applied in wireless network widely and achieved impressive performance. In recent years, in order to mine the topology information of graph-structured data in wireless network as well as contextual information, graph neural networks have been introduced and have achieved the state-of-the-art performance of a series of wireless network problems. In this review, we first simply introduce the progress of several classical paradigms, such as graph convolutional neural networks, graph attention networks, graph auto-encoder, graph recurrent networks, graph reinforcement learning and spatial-temporal graph neural networks, of graph neural networks comprehensively. Then, several applications of graph neural networks in wireless networks such as power control, link scheduling, channel control, wireless traffic prediction, vehicular communication, point cloud, etc., are discussed in detail. Finally, some research trends about the applications of graph neural networks in wireless networks are discussed."
        },
        {
            "title": "Efficient Quantum Transforms",
            "summary": "Quantum mechanics requires the operation of quantum computers to be unitary, and thus makes it important to have general techniques for developing fast quantum algorithms for computing unitary transforms. A quantum routine for computing a generalized Kronecker product is given. Applications include re-development of the networks for computing the Walsh-Hadamard and the quantum Fourier transform. New networks for two wavelet transforms are given. Quantum computation of Fourier transforms for non-Abelian groups is defined. A slightly relaxed definition is shown to simplify the analysis and the networks that computes the transforms. Efficient networks for computing such transforms for a class of metacyclic groups are introduced. A novel network for computing a Fourier transform for a group used in quantum error-correction is also given."
        },
        {
            "title": "Stone Age Distributed Computing",
            "summary": "The traditional models of distributed computing focus mainly on networks of computer-like devices that can exchange large messages with their neighbors and perform arbitrary local computations. Recently, there is a trend to apply distributed computing methods to networks of sub-microprocessor devices, e.g., biological cellular networks or networks of nano-devices. However, the suitability of the traditional distributed computing models to these types of networks is questionable: do tiny bio/nano nodes \"compute\" and/or \"communicate\" essentially the same as a computer? In this paper, we introduce a new model that depicts a network of randomized finite state machines operating in an asynchronous environment. Although the computation and communication capabilities of each individual device in the new model are, by design, much weaker than those of a computer, we show that some of the most important and extensively studied distributed computing problems can still be solved efficiently."
        },
        {
            "title": "Performance Metrics Analysis of Torus Embedded Hypercube Interconnection   Network",
            "summary": "Advantages of hypercube network and torus topology are used to derive an embedded architecture for product network known as torus embedded hypercube scalable interconnection network. This paper analyzes torus embedded hypercube network pertinent to parallel architecture. The network metrics are used to show how good embedded network can be designed for parallel computation. Network parameter analysis and comparison of embedded network with basic networks is presented."
        },
        {
            "title": "A network model with structured nodes",
            "summary": "We present a network model in which words over a specific alphabet, called {\\it structures}, are associated to each node and undirected edges are added depending on some distance between different structures. It is shown that this model can generate, without the use of preferential attachment or any other heuristic, networks with topological features similar to biological networks: power law degree distribution, clustering coefficient independent from the network size, etc. Specific biological networks ({\\it C. Elegans} neural network and {\\it E. Coli} protein-protein interaction network) are replicated using this model."
        },
        {
            "title": "Data taking network for COMET Phase-I",
            "summary": "An experiment to search for mu-e conversion named COMET is being constructed at J-PARC. The experiment will be carried out using a two-stage approach of Phase-I and Phase-II. The data taking system of Phase-I is developed based on common network technology. The data taking system consists of two kinds of networks. One is a front-end network. Its network bundles around twenty front-end devices that have a 1-Gb optical network port. And a front-end computer accepts data from the devices via its network. The other is a back-end network that collects all event fragments from the front-end computers using a 10-Gb network. We used a low price 1Gb/10Gb optical network switch for the front-end network. And direct connection between the front-end PC and an event building PC using 10-Gb optical network devices was used for the back-end network. The event building PC has ten 10-Gb network ports. And each network port of the event building PC is connected to the front-end PC's port without using a network switch. We evaluated data taking performance with an event building on these two kinds of networks. The event building throughput of the front-end network achieved 337 MiB/s. And the event building throughput of the back-end networks achieved 1.2 GiB/s. It means that we could reduce the construction cost of the data taking network using this structure without deteriorating performance. Moreover, we evaluated the writing speed of the local storage RAID disk system connected to a back-end PC by a SAS interface, and a long-distance network copy from the experiment location to the lasting storage."
        },
        {
            "title": "A Survey on Mobile Edge Networks: Convergence of Computing, Caching and   Communications",
            "summary": "As the explosive growth of smart devices and the advent of many new applications, traffic volume has been growing exponentially. The traditional centralized network architecture cannot accommodate such user demands due to heavy burden on the backhaul links and long latency. Therefore, new architectures which bring network functions and contents to the network edge are proposed, i.e., mobile edge computing and caching. Mobile edge networks provide cloud computing and caching capabilities at the edge of cellular networks. In this survey, we make an exhaustive review on the state-of-the-art research efforts on mobile edge networks. We first give an overview of mobile edge networks including definition, architecture and advantages. Next, a comprehensive survey of issues on computing, caching and communication techniques at the network edge is presented respectively. The applications and use cases of mobile edge networks are discussed. Subsequently, the key enablers of mobile edge networks such as cloud technology, SDN/NFV and smart devices are discussed. Finally, open research challenges and future directions are presented as well."
        },
        {
            "title": "On Network Coding Capacity - Matroidal Networks and Network Capacity   Regions",
            "summary": "One fundamental problem in the field of network coding is to determine the network coding capacity of networks under various network coding schemes. In this thesis, we address the problem with two approaches: matroidal networks and capacity regions.   In our matroidal approach, we prove the converse of the theorem which states that, if a network is scalar-linearly solvable then it is a matroidal network associated with a representable matroid over a finite field. As a consequence, we obtain a correspondence between scalar-linearly solvable networks and representable matroids over finite fields in the framework of matroidal networks. We prove a theorem about the scalar-linear solvability of networks and field characteristics. We provide a method for generating scalar-linearly solvable networks that are potentially different from the networks that we already know are scalar-linearly solvable.   In our capacity region approach, we define a multi-dimensional object, called the network capacity region, associated with networks that is analogous to the rate regions in information theory. For the network routing capacity region, we show that the region is a computable rational polytope and provide exact algorithms and approximation heuristics for computing the region. For the network linear coding capacity region, we construct a computable rational polytope, with respect to a given finite field, that inner bounds the linear coding capacity region and provide exact algorithms and approximation heuristics for computing the polytope. The exact algorithms and approximation heuristics we present are not polynomial time schemes and may depend on the output size."
        },
        {
            "title": "An Effective Fusion Technique of Cloud Computing and Networking Series",
            "summary": "Cloud computing is making it possible to separate the process of building an infrastructure for service provisioning from the business of providing end user services. Today, such infrastructures are normally provided in large data centres and the applications are executed remotely from the users. One reason for this is that cloud computing requires a reasonably stable infrastructure and networking environment, largely due to management reasons. Networking of Information (NetInf) is an information centric networking paradigm that can support cloud computing by providing new possibilities for network transport and storage. It offers direct access to information objects through a simple API, independent of their location in the network. This abstraction can hide much of the complexity of storage and network transport systems that cloud computing today has to deal with. In this paper we analyze how cloud computing and NetInf can be combined to make cloud computing infrastructures easier to manage, and potentially enable deployment in smaller and more dynamic networking environments. NetInf should thus be understood as an enhancement to the infrastructure for cloud computing rather than a change to cloud computing technology as such. To illustrate the approach taken by NetInf, we also describe how it can be implemented by introducing a specific name resolution and routing mechanism."
        },
        {
            "title": "A Tutorial on Network Security: Attacks and Controls",
            "summary": "With the phenomenal growth in the Internet, network security has become an integral part of computer and information security. In order to come up with measures that make networks more secure, it is important to learn about the vulnerabilities that could exist in a computer network and then have an understanding of the typical attacks that have been carried out in such networks. The first half of this paper will expose the readers to the classical network attacks that have exploited the typical vulnerabilities of computer networks in the past and solutions that have been adopted since then to prevent or reduce the chances of some of these attacks. The second half of the paper will expose the readers to the different network security controls including the network architecture, protocols, standards and software/ hardware tools that have been adopted in modern day computer networks."
        }
    ],
    "numerical+analysis": [
        {
            "title": "Analysis of Flux Corrected Transport Schemes for Evolutionary   Convection-Diffusion-Reaction Equations",
            "summary": "We report in this paper the analysis for the linear and nonlinear version of the flux corrected transport (FEM-FCT) scheme in combination with the backward Euler time-stepping scheme applied to time-dependent convection-diffusion-reaction problems. We present the stability and error estimates for the linear and nonlinear FEM-FCT scheme. Numerical results confirm the theoretical predictions."
        },
        {
            "title": "What is wrong with the Lax-Richtmyer fundamental theorem of linear   numerical analysis ?",
            "summary": "We show that the celebrated 1956 Lax-Richtmyer linear theorem in Numerical Analysis - often called the Fundamental Theorem of Numerical Analysis - is in fact wrong. Here \"wrong\" does not mean that its statement is false mathematically, but that it has a limited practical relevance as it misrepresents what actually goes on in the numerical analysis of partial differential equations. Namely, the assumptions used in that theorem are excessive to the extent of being unrealistic from practical point of view. The two facts which the mentioned theorem gets wrong from practical point of view are : - the relationship between the convergence and stability of numerical methods for linear PDEs, - the effect of the propagation of round-off errors in such numerical methods. The mentioned theorem leads to a result for PDEs which is unrealistically better than the well known best possible similar result in the numerical analysis of ODEs. Strangely enough, this fact seems not to be known well enough in the literature. Once one becomes aware of the above, new avenues of both practical and theoretical interest can open up in the numerical analysis of PDEs."
        },
        {
            "title": "Numerical Approximations and Error Analysis of the Cahn-Hilliard   Equation with Dynamic Boundary Conditions",
            "summary": "We consider the numerical approximations of the Cahn-Hilliard equation with dynamic boundary conditions (C. Liu et. al., Arch. Rational Mech. Anal., 2019). We propose a first-order in time, linear and energy stable numerical scheme, which is based on the stabilized linearly implicit approach. The energy stability of the scheme is proved and the semi-discrete-in-time error estimates are carried out. Numerical experiments, including the comparison with the former work, the accuracy tests with respect to the time step size and the shape deformation of a droplet, are performed to validate the accuracy and the stability of the proposed scheme."
        },
        {
            "title": "Matching Component Analysis for Transfer Learning",
            "summary": "We introduce a new Procrustes-type method called matching component analysis to isolate components in data for transfer learning. Our theoretical results describe the sample complexity of this method, and we demonstrate through numerical experiments that our approach is indeed well suited for transfer learning."
        },
        {
            "title": "Numerical evaluation of Airy-type integrals arising in uniform   asymptotic analysis",
            "summary": "We describe a method to evaluate integrals that arise in the asymptotic analysis when two saddle points may be close together. These integrals, which appear in problems from optics, acoustics or quantum mechanics as well as in a wide class of special functions, can be transformed into Airy-type integrals and we use the trapezoidal rule to compute these integrals numerically. The quadrature method, which remains valid when two saddle points coalesce, is illustrated with numerical examples."
        },
        {
            "title": "Sharp numerical inclusion of the best constant for embedding   $H_{0}^{1}(\u03a9) \\hookrightarrow L^{p}(\u03a9)$ on bounded convex domain",
            "summary": "In this paper, we propose a verified numerical method for obtaining a sharp inclusion of the best constant for the embedding $H_{0}^{1}(\\Omega) \\hookrightarrow L^{p}(\\Omega)$ on bounded convex domain in $\\mathbb{R}^{2}$. We estimate the best constant by computing the corresponding extremal function using a verified numerical computation. Verified numerical inclusions of the best constant on a square domain are presented."
        },
        {
            "title": "Numerical scheme based on the spectral method for calculating nonlinear   hyperbolic evolution equations",
            "summary": "High-precision numerical scheme for nonlinear hyperbolic evolution equations is proposed based on the spectral method. The detail discretization processes are discussed in case of one-dimensional Klein-Gordon equations. In conclusion, a numerical scheme with the order of total calculation cost $O(N \\log 2N)$ is proposed. As benchmark results, the relation between the numerical precision and the discretization unit size are demonstrated."
        },
        {
            "title": "Convergent non complete interpolatory quadrature rules",
            "summary": "We find a family of convergent schemes of nodes for non-complete interpolatory quadrature rules."
        },
        {
            "title": "On different definitions of numerical range",
            "summary": "We study the relation between the intrinsic and the spatial numerical ranges with the recently introduced \"approximated\" spatial numerical range. As main result, we show that the intrinsic numerical range always coincides with the convex hull of the approximated spatial numerical range. Besides, we show sufficient conditions and necessary conditions to assure that the approximated spatial numerical range coincides with the closure of the spatial numerical range."
        },
        {
            "title": "Numerical Method for Solving Obstacle Scattering Problems by an   Algorithm Based on the Modified Rayleigh Conjecture",
            "summary": "A numerical algorithm is presented for solving the direct scattering problems by the Modified Rayleigh Conjecture Method   (MRC) introduced by A.G.Ramm. Some numerical examples are given. They show that the method is numerically efficient."
        }
    ]
}